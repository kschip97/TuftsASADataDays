---
title: "An Introduction to R"
author: "Kees Schipper"
date: "3/25/2021"
output: 
  html_document:
    toc: True
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(tidyverse)
library(todor)
todor()
```

# 0.0-Introduction:

This markdown is meant to be a quick introduction to get students up to speed with basic R concepts. Many of the concepts covered here were pulled from some of the operations I use in everyday programming. My hope is that this script will be a quick (but not necessarily comprehensive) introduction to get students up to speed with programming in R. I will be including the Rmarkdown script to this HTML document so that students can experiment with different code chunks, and really practice the concepts that I will be presenting.

This markdown document will be available to view and download from my github while in production. Just keep in mind that just because a topic isn't covered on this document doesn't mean that it won't be covered in the future. I'm considering this as a working document, and it likely will be for a very long time

# 1.0-Basic Arithmetic

```{r}
10 + 7
10 - 7
10 * 7
10 / 7
10 ** 7
10 ^ 7
10 %/% 7 # modulus is floor division. It takes the result of 10/7 and rounds down to the next integer
10 %% 7 # %% is the reverse of the modulus, as it returns the remainder of 10/7


```


# 2.0-Storing data in variables

In R, you can use two different operators to store data in the form of a variable. You could go for the traditional `=` to store information, like saying `x = 15*25`. However, best practices in R is to use the assignment operator, `<-`, as in `x <- 15*25`. Intuitively, this can be read as "Storing the result of 15*25 into the variable x".

```{r variables}

x = 15*25
print(x)
x <- 15*25
print(x)
## same result
```

However, variables can store much more than single numbers. Variables can store just about anything in R. Variables can store things like formulas: `outcome ~ pred1 + pred2 + pred3` used for making models. You can also store strings, lists, factors, data frames, vectors, plots and complicated visuals. Almost anything you can imagine in R can be stored as a variable.


# Data types

R has very multiple data types. Some common ones include strings/character data (`"Things surrounded by quotes"`), factor/categorical data, numeric/double, integer, date, and boolean.

```{r}
# examples of making different data types
string <- "simple string"
print(string)
numeric <- 1
print(numeric)
double <- 3.141592
print(double)
date <- Sys.Date()
print(date)
factor_data <- as.factor(c("King", "Queen", "Rook"))
print(factor_data)
bool <- 1 == 1
bool
otherbool <- 1 > 5
otherbool
```

## Vectors

Vectors can be considered as 1-dimensional collections of data. By 1-dimensional, I mean that a vector can either have 1 row and many columns, or one column and many rows (it really doesn't make a difference). There are a bunch of ways to make vectors in R, but the two most common ones are the `c()` function for combining data elements, and the `vector()` function, which actually lets you make much more than just a vector

```{r Vector}
vec1 <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
vec1
# you can also make this vector much more simply with the seq() function
vec2 <- seq(1, 10, by = 1)
vec2
vec1 == vec2

vector(mode = "double", length = 50) # this creates an empty vector that you can populate later

```


## Indexing

Indexing is relatively straightforward in R. Elements in a data structure are intuitively indexed from 1 to however many data elements are in that structure. For example, a vector holding the letters of the alphabet would be indexed with "a" having an index of 1, "b" with an index of 2, and "c" having an index of 3...

### Indexing Vectors

We can easily index elements with square brackets placed after the variable that a vector is stored in:

```{r}
vec1 <- seq(500, 1, by = -15)
print(vec1)
vec1[1] # the first element
vec1[length(vec1)] # the last element
```

You can also specify a range of elements that you want to index

```{r}
vec1[5:25]

# or we can grab every other index
vec1[seq(5, 25, by = 2)]

# or we can remove an element by its index
vec3 <- vec1[-c(15, 25, 30)]
vec1
vec3
```

We can also index using boolean values (TRUE/FALSE). How booleans work is that you provide a comparison or operation such as greater than `>`, less than `<`, greater than or equal to `>=`, less than or equal to `<=`, equal to `==`, **not** equal to `!=`, is missing (or NA) `is.na()`, is **not** missing (or NA) `!is.na()`, etc... that compares two pieces of data based on a certain condition. Notice that the exclamation point (called a "bang" in R terminology), simply negates whatever operation follows it (this can be extremely useful in letting the user define their own operations). I'll include some simple booleans below

```{r}
x <- NA
y <- 5
z <- 10

is.na(x)
!is.na(x)
y < z
y > z
y <= z
y >= z
y == z
y != z

```

The cool thing that we can do with these boolean TRUE/FALSE values, is that we can use them to index our data with specific conditions! If we place a boolean comparison within `[]`, R will evaluate whether elements in the data structure are TRUE or FALSE, keeping the TRUE values, and removing the FALSE values.

First I'll show you whats happening before the indexing

```{r}
vec1 < 250
vec1
```

Now, if we use `vec1 < 250` as an indexer, we'll get a vector returned that should only have the values of 245 to 5

```{r}
vec1[vec1 < 250]
```

Indexing is extremely useful, as it opens up the ability for us to select subsets of our data, clean data, and view specific portions of our data that we are interested in. We can also split our data into groups for subgroup analyses. I'll just show a couple other indexing operations

```{r}
vec1[vec1 > 250]
vec1[vec1 != 245]
vec1[is.na(vec1)]

# you can also chang the value of an element in a vector using the assignment operator

vec1[vec1 == 245] <- 246 # a fun way to mess with friends
vec1
```

If you are ever confused about what your index will return, simply run the boolean statement by itself, and view the TRUE/FALSE values to see if your index would keep what you want. As you can see, none of our vec1 values are `NA`, so our last index returned an empty numeric vector.


## Lists

Lists are interesting as a data structure, because they can be used to collect a bunch of different data types into one storage unit. Whereas the vectors I've made have only contained numbers, lists can contain numbers, boolean values, other lists, data frames, plots and figures, functions, formulas, and pretty much anything else you could want. Let's make a wonky list

```{r}


mylist <- list(FALSE, 100, outcome ~ first + second + third, "random string for good measure", 1:500, mean(1:500))

# you can also give names to list attributes. Here, I'll make the same list but each element will have a name

mylist_named <- list(bool = FALSE, hund = 100, formula = outcome ~ first + second + third, string = "random string for good measure", range = 1:500, mean = mean(1:500))

```


### Indexing lists

Indexing lists is a little bit different than with simple vectors or data frames, which we will cover next. You can pull elements from lists using a double bracket operator `[[]]`. This double bracket explicitly takes a single object from a list and returns it to you. You can either use the numerical index of the object you want, or you can use the explicit name that the object is given in the list. I'll show you two ways of getting the same thing

```{r}
mylist_named[[2]]
mylist_named[["hund"]]
```

In this way, you can access elements of your list either using a numerical index, or the key that is provided for that list. There is also one more way to extract elements from a list, and that is with the convenient `$` operator. This operator also lets you use autocomplete if you aren't sure of the name of the thing that you want in your list

```{r}
mylist_named$bool
mylist_named$formula
```

Lists are extremely important to know how to work with, as many functions in R return output in the form of a list. Some examples are the `summary` function, the `lm` and `glm` functions for making models. You can also reassign portions of lists using indexing and the assignment operator

```{r}
mylist_named$formula <- outcome ~ three + two + one
mylist_named$formula
```

## Data frames

Data frames can be conceptualized as the equivalent of an excel spreadsheet in R. If you want a more complex explanation, Data frames are a list of column vectors, where each vector has a name (this has implications for indexing data frames later). Let's stick with the first explanation for now, as it's less confusing and most people have worked with excel before. Creating data frames are simple, but often you will get a data frame from a .csv file or off of the internet rather than making them yourself

```{r}

random_data <- data.frame(letters = c("a", "b", "c", "d"),
                          numbers = c(1, 2, 3, 4),
                          bools = c(T, F, T, F),
                          factor = as.factor(c("High", "Medium", "Low", "Just Right")),
                          date = as.Date(c("2020-01-05", "1000-05-03", "2021-01-01", "1980-05-07")))
random_data

```

If we consider each column of the data frame to be a single vector that is part of a 'list', then we can index columns the same way that we would index elements of a list, except that now, we can also index data frames using single brackets, with `[row, column]` specification. Note: if you want to extract all rows from a single column, or all columns from a single row, leave the respective row or column element blank.

```{r}
random_data$bools
random_data[['bools']]
random_data[, 3] 
# note as data frames are 2-dimensional structures, you have to specify what rows you want.
# We want the entire column of bools, which is the third column, but to specify the rows, we just leave
# the rows element blank. In data frames, the structure of indexing is [rows, columns].
```

If we want specific rows of our data frame, we can do that as well, either using boolean indexing or numbers

```{r}
random_data[1:3, ]
random_data[random_data$letters == "a",] # select the row where letters is equal to a, and keep all columns
```

We can also do some chain indexing, which allows us to first select a column, and then select an element of that column that we're interested in

```{r}
random_data

random_data$letters[2]

random_data[["numbers"]][3]
# intuitively, here we are selecting a vector, called numbers, and then getting the third element from it

# or we could keep both column and row indexes in the same index
random_data[2, 3]

```


### Making new variables

We can easily make new variables for data frames with the `$` operator

```{r}
random_data$newvar <- rep(c("silly", "billy"), 2)
random_data
```

we can also change variable names using the `names()` function

```{r}
names(random_data)
names(random_data)[3]
names(random_data)[3] <- "TrueFalse"
random_data
```


# Installing and Using Packages

Packages increase the range of functionality in your R scripts. However, if there is something that is extremely simple to do, don't rely on an external package to do it. Oftentimes packages can change, functions become deprecated, and the world moves on. If you write the code for a function yourself, you don't have to worry about things changing. That being said, R is very good about maintaining packages and keeping them functional. Just make sure you know what a function does before you use it for getting research results

You only need two functions for package management: `install.packages()` does what is says it does, and `library()` activates your package within your R session. An added bonus is the `require()` function, which checks if the package doesn't exist in your library. If the package doesn't exist, require returns a `FALSE` value and a warning, whereas `library()` throws an error. If you're sharing packages with colleagues, you can include the following at the top of your code for each package that is required to run your script:

`if !require("packagename"); install.packages("packagename"); library(packagename)`

Read left to right in plain english the above statement says: If this package does not exist, install this package, and then activate the package from the library. This line of code will only install a package if it does not exist in the current library, and prevents unwanted updates if someone already has the package installed. That being said, if you want to update a package, just run `install.packages()` on that package again.

# Functions

I've already used a couple in this demo, but functions are simply large chunks of code, represented by a function name that takes what are called arguments, and do *stuff* with them.

The general format of a function is `funcName(arg1, arg2, arg3...)`. Arguments are things supplied to the function by the user that either changes the settings of the function or gives the function something to operate on.

## Using built-in functions

There are too many built-in functions to use in R for me to go over, so I'll just list a couple helpful base functions that I find helpful in looking at data. I recommend looking at the documentation of some of these functions to get an idea of how they work, and maybe you could implement some of them into your scripts

```{r}
# for basic summary statistics
mean
min
max
median
sd
var
quantile
summary

# for working with strings
paste
paste0
substr

# pattern matching
grep
grepl

# finding the index of something
which

# simple plotting
plot
boxplot
hist

# Exploring the type of your data
class
str

# for making data frames, lists, vectors, and concatenating
data.frame
as.data.frame
list
vector
matrix
c

# and if you ever want to explore what a function does, type the name of the function in the console, and press enter after it. This will pull up the code contained in the function. Reading source code is a bit of an advanced topic, but it's a good way to see how others write their functions, and can give you an idea of what's happening under the hood
```

## Creating your own functions

If you can't find a function that suits your needs, or you want to automate a repetitive piece of your data cleaning, you can simply make your own function. The syntax is simple, as I will show below

```{r}
addfunc <- function(arg1, arg2){
  output <- arg1 + arg2
  return(output)
}

addfunc(1, 5)
addfunc(-5, -20)

```

The simple `addfunc` that I made above is about as basic as a function can get, you can also make functions outputting strings, or really anything. To end a function and be sure you get the output that you want, simply use the `return()` function, and whatever you put inside the brackets of `return` will be returned as output. Here's another example of a function that will say hi to you if you give it your name

```{r}
SayHi <- function(name){
  greeting <- paste0("Hello ", name, ", nice to meet you")
  return(greeting)
}

SayHi(name = "Kees")
```

you can also store the output of a function as a variable with the following syntax:

```{r}
StoreGreeting <- SayHi(name = "Kees")
print(StoreGreeting)
```

Some details:

+ in the `SayHi` function, `name` is a function argument. The function takes a value for the argument of `name`, and evaluates any values of `name` inside the function as that value. 
+ A simple way to visualize this is to look at the body of the `SayHi` code. Any location where you see the variable `name`, the string "Kees" will be substituded there. This is a basic overview of how arguments work inside of functions. 
+ Obviously, there are more complicated applications of functions, but once you have the basic syntax, and understand how arguments and the `return` function works, you're at a good starting point

### Control flow (AKA if...else if...else)

You can use what is called "control flow" to have your script make analysis decisions for you! This is an extremely powerful capability that's available in every programming language you ever see, so once you learn how to use if-else ======= in R, you can use this concept in any other programming language.

If-else statements work as follows:

+ You provide an If statement with a statement that evaluates to TRUE or FALSE
  + If the statement evaluates to TRUE, the code underneath the if statement is executed
  + If the statement evaluates to FALSE, the code underneath the if statement is ignored
+ If the first `if` statement evaluates to false, the code proceeds to the next chunk, or an `else if` statement
  + The else if statement behaves the same as the first `if` statement, however this statement allows you to supply a different condition for your code to execute on. If this new statement evaluates to TRUE, the code below the `else if` statement is executed. If FALSE, R will ignore the code within that `else if` statement.
+ Finally, if all of your previous `if` and `else if` statements fail, you can conclude your `else if` chain with an `else` statement.
  + Intuitively, an `else` statement can be interpreted as such: "Else, if all of the above conditions that you provided for me evaluate to FALSE, run the code below."
+ A final point, In an `if...else` chain, R will evaluate the first TRUE `if` statement it sees, and ignore all other statements that come after in that `if...else` chain. Because of this, the order of your `if...else` statements might be important to consider when you are writing code.

`if...else` statements are great to include in functions to give your users multiple options for how to evaluate a chunk of code. Let's adjust our greeting function so that it greets you based on the time of day you provide.

```{r}
library(lubridate)

SayHiTOD <- function(name){
  hour <- hour(as.character(Sys.time())) 
  hour.num <- as.numeric(hour)
  # Sys.time provides the current DATETIME, while hour extracts the hour (0-24) of the current date
  
  if (hour < 12){
    greeting <- paste0("Good Morning ", name, ", I hope you have a great day!")
  } else if (hour >= 12 & hour < 17){
    greeting <- paste0("Good afternoon ", name, ", I hope you're having a great day!")
  } else {
    greeting <- paste0("Good evening ", name, ", I hope you've had a great day!")
  }
  return(greeting)
}

SayHiTOD("Kees")
```

The above function still only takes a name as an argument, but it has code in the body that provides the time of the day (with the `Sys.time()` function). Then, based on the hour extracted from `Sys.time()`, R evaluates an if statement based on whether it is morning, early afternoon, or evening, and gives you a greeting specific to the time. You could alternatively ask the use to provide the hour as an argument, but you never know if the user might be lying to you...

Later on, when we get to `dplyr`, I'll show you how you can make custom functions that take a file, data frame, or other type of data structure with similar elements, and automate the data cleaning process using a function with `dplyr` verbs. In the end, we'll make a function that creates summary tables based on the provided data set.

### for loops and while loops

For and while loops play off of indexing that I showed you before. However, loops allow you to "loop" through multiple elements with one chunk of code. For example, say you wanted to insert a time series variable into a data frame (that would count from 1 in row 1 to the end of your data frame). You could use a for loop to generate such a variable (there are other ways, but this is for the sake of demonstration).

For loop syntax is very simple, just like functions. You start with a `for` or `while` statement, followed by parentheses, showing the range that you are going to loop through, and specifying the index that you are going to use `(i in 1:50)`, and then you have a set of brackets that contains the code you are going to be iterating through. I'll show you the most basic for loop that you can probably make

```{r}
for (i in 1:10){
  cat("This is iteration ", i, " of ", 10, "\n")
  Sys.sleep(0.5)
}
```

The above for loop just prints a message as to what iteration the loop is on. The way the for loop works is that the loop runs through all of the contained code within the curly braces, and then starts on the next iteration. All the while, `i` starts as 1, then is 2 in the next loop, then 3, then 4, etc... 

As you could imagine, we can use that `i`, or that index to iterate through a dataframe, list, or anything that has an inherent index to it. Let's look at the ChickWeight dataset contained within R, which has data on a chick's weight, the time from birth, the Chick identification number, and the Diet that the chick was placed on. I'll help us visualize the data with a quick plot

```{r}

ggplot(data = ChickWeight, aes(x = Time, y = weight, group = Chick, color = Diet)) +
  geom_line() +
  labs(title = "Chickweight Over Time By Diet")

```

There are a couple ways that we could cycle through a data frame. One way to do this is with the `seq_along()` function. In this function, you provide a vector, list, or one-dimensional data structure, and this function generates a sequence of indices that matches the provided data structure. For example, we could do `seq_along(names(ChickWeight))`, and our for loop would iterate from 1 to the number of columns in our dataframe Chickweight

```{r}
for (col in seq_along(names(ChickWeight))){
  cat("Column ", col, " in ChickWeight is named ", names(ChickWeight)[col], "\n")
}
```

We could also use the functions `nrow` and `ncol` to iterate through the number of columns or the number of rows in a data frame

```{r}
for (row in 1:nrow(ChickWeight)){
  
  cat(ChickWeight$Diet[row], "; ")
  
}


```

Above, you can see all of the values in the ChickWeight column `Diet`, separated by semicolons. Obviously there are more useful things that you can do with this, but this is just an example of how you could access elements of a dataframe using a for loop. You could also change values of a dataframe using a for loop just as easily. Let's say that all of the values for ChickWeight are wrong, and values of 1 should be 4, 2 should be 3, 3 should be 2, and 4 should be 1. We could use a for loop to correct this error

```{r}
for (i in 1:nrow(ChickWeight)){
  if (ChickWeight$Diet[i] == 4){
    ChickWeight$Diet[i] <- 1
  } else if (ChickWeight$Diet[i] == 3){
      ChickWeight$Diet[i] <- 2
  } else if (ChickWeight$Diet[i] == 2){
      ChickWeight$Diet[i] <- 3
  } else if (ChickWeight$Diet[i] == 1){
      ChickWeight$Diet[i] <- 4
  }
  
}

head(ChickWeight$Diet)
tail(ChickWeight$Diet)
```

Notice that you should be careful with these types of operations above, as if you don't use the else if statement, the for loop will change values of 4 into values of one, and then when they reach the last statement, they will change the values of 1 back into a 4. It is important that you string together these statements utilising `else if`.

I will only cover while loops for a little bit, as I've barely found the need to use a while loop in my scripts. While loops are like for loops, except that while loops continue looping until a provided condition is met, or a break statement is implemented. Let me show you what I mean

```{r}
i <- 0
while (i < 15) {
  print(i)
  i <- i + 1
}
```

Here you see with while loops that our index, `i` was printed continuously, until we reached 15, after which our while loop terminated. The intuitive way to read a while loop is through the following steps

+ read the condition next to the while statement. If the condition evaluates to TRUE, the code in the while loop will execute
+ Go back to the top of the while loop. Is the condition still TRUE? if so, the code will be run again. If FALSE, the while loop will terminate.

Another way that while loops are different from for loops are that we have to explicitly create an iterator. If we hadn't defined i above the while loop, our while loop wouldn't know what we're talking about when we tell it to print I.

One other thing, within the while loop, we have to do something to change the iterator. If we didn't have the `i <- i + 1 statement` in our loop, our loop would never end, which is super annoying and has happened to me multiple times. Don't write infinite while loops...please...

Another way that you could stop a while loop is with a `break` statement, which causes your code to terminate the while loop, regardless of whether the while loop has met its condition or not. Sometimes you don't know how long your while loop will run, so you can use some `if...else` logic and a break statement to cut off your while loop whenever a condition is met. Check out this example

```{r}
i <- 1
while (TRUE){
  r <- runif(1, min = 0, max = 50000)
  
  if (r > 49950){
    print(r)
    cat("We got greater than 49950 in ", i, " iterations")
    break
  }
  
  i <- i + 1
}
```

`runif` produces a random number from a uniform distribution between min and max, `break` stops our while loop whenever we get a number greater than 49950, and the `while (TRUE)` syntax just tells our while loop to run indefinitely until we hit a break.

This brings up another point with `if...else` and `while` statements. If you provide just a number that is either 1 or greater, that number will always be interpreted as a true statement, while 0 is evaluated as a FALSE. This has some uses if you want to stop a loop on a zero, or just want to make sure that you have a number stored in a value before proceeding through the rest of your loop.

## Code Snippets for saving time

R has what are called "snippets," which are pre-typed sections of code syntax that you can pull up with auto-complete. some common snippets to use can write out `if...else` statements, function and loop syntax. All you have to do is type the first couple letters of `for`, `while`, `function`, and other statements, and hit the tab button, and autocomplete will do the rest. Here's what these snippets will give you

```{r eval=FALSE, echo = T}
for (variable in vector) {# for
  
}

while (condition) {# whil
  
}

name <- function(variables) {# func
  
}

if (condition) { # if
  
} else if (condition) { # ei
  
} else { # el
  
}

#lap
lapply(list, function)
#sap
sapply(list, function)
# lib
library(package)
# req
require(package)

# you can even make your own code snippets. For example, I made one called 'header'
# which creates a reproducible header that I can put at the top of every script

# here's my header snippet


## Script_Name.R             
## Programmer: Kees Schipper 
## Created: 2021-04-04       
## Last Updated: 2021-04-04
############################################################
## Clean up global environment
dev.off()
rm(list = ls())
############################################################
## Set up Packages
library(tidyverse)


############################################################
## Notes: Type notes for TODOs and usage of code here

############################################################
## Set your working directory
setwd()




```

# Base Plotting

## The `plot` function

## The `boxplot` function

## The `hist` function

# Package Spotlights

## dplyr

```{r}
# TODO: Edit dplyr section to read like the sections preceding, with explanations and examples.
# Introduction to dplyr functions -----------------------------------------
# load in the data
library(tidytuesdayR)
Kenya_All <- tt_load(2021, week = 4)
Kenya_All

House <- Kenya_All$households


# ?magrittr::`%>%`
# ?dplyr::select
# ?dplyr::filter
# ?dplyr::mutate
# ?dplyr::arrange
# ?dplyr::group_by
# ?dplyr::summarize
# ?dplyr::rename
```


```{r}
# %>% or the pipe operator ------------------------------------------------
# f(x) is the same thing as x %>% f()

x <- c(1, 2, 3, 4, 5)
sum(x)
x %>% sum()
```


```{r}
# select and helper functions ---------------------------------------------
# look at the column names in a data set
names(House)

# basic use of the select function. Get columns for pop and households
select(House, Population, NumberOfHouseholds)

# same as the above code but with a pipe
House %>% 
  select(County, Population)

# viewing but not storing output. Using `:` to specify a range of columns
House %>%
  select(County:NumberOfHouseholds) %>% View()

# storing your piped operations into a new data frame
House_cleaned <- House %>%
  select(County:NumberOfHouseholds)

# negative selection: read as "I want to remove columns 1 through 3 from my data set
House %>%
  select(-c(1:3))

# use pipes to string together multiple functions (rm avghousesize and rename population)
House %>%
  select(-AverageHouseholdSize) %>%
  rename(Pop = Population)

# reorder rows by specifying from left-to-right the order of rows that you want
House %>% select(Population, everything())

# selects all columns that match but don't throw an error if one entry doesn't match
House %>% select(any_of(c("County", "notacolumn", "Population")))

# ?starts_with
# ?ends_with
# ?contains
# ?matches # regular expression matching...maybe a little too complicated to explain
# ?num_range
# ?everything
# ?last_col
# ?all_of
# ?any_of

# ?where # a lot of really cool use-cases with this function. where allows the user to select
#        # columns based on a function. Function must result in TRUE or FALSE outputs to be used
#
```


```{r}
# filtering: similar to select but for rows -------------------------------
# boolean/relational operators:
# ?`<` #less thaopulationn
# ?`>` #greater than
# ?`<=` #less than or equal to
# ?`>=` #greater than or equal to
# ?`==` #is equal to
# ?`!=` #is not equal to
# ?between # if you want a faster way of specifying a range
# ?`|` # bitwise "or"
# ?`&` # bitwise "and"
# ?`||` # Or for control flow
# ?`&&` # And for control flow
# can filter data by boolean operations. With filter(), referring to column names
# directly within the filter function
House_filter <- House %>%
  filter(Population < 605415 & !is.na(Population))

# can also compare variables in a dataset to set values 
MedPop <- median(House_filter$Population)

House_filter %>%
  filter(Population < MedPop)


# for || and &&, if the first condition is not met, the if statement returns a FALSE
# immediatesly, whereas with & and |, both elements of the boolean statement are checked
```


```{r}
# mutate: for creating new variables --------------------------------------

# create new variables based on old ones
House %>%
  mutate(NumbHouse = Population/AverageHouseholdSize)

# base R version: less neat IMO
House$NumbHouse = House$Population/House$AverageHouseholdSize

# summarize: for creating aggregate summaries of data ---------------------
library(moments) # for skewness and kurtosis


House_new <- House[2:nrow(House), ]

House_new %>%
  summarise(sd_pop = sd(Population),
            kurt_pop = kurtosis(Population),
            med_house = median(NumbHouse),
            avg_hsize = mean(AverageHouseholdSize),
            stderr_pop = sd(Population)/n(),
            N = n(),
            nMiss = sum(is.na(Population)),
            Ncomp = sum(!is.na(Population)))

# ?complete.cases()
# ?min()
# ?max()
# ?quantile()
```


```{r}
# group_by: for making summaries and vars group-specific ------------------
group_data <- starwars

# group_by creates implicit groups in your data to perform group-wise operations
# remember: group_by doesn't perform any operations on our data, but the groupings
# are applied to operations later on 

group_data %>%
  group_by(eye_color) %>%
  summarise(grp_mass = mean(mass, na.rm = T))

group_data %>%
  group_by(eye_color, skin_color) %>%
  summarise(grp_mass = mean(mass, na.rm = T))

```

```{r Summarise}
# TODO: Need to make a section on the summarise function
```


## `readr`, `haven`, ``readxl``, and other functions for reading data

# Exploratory Data Analysis-Summary statistics and groupings

## Base R

## Dplyr

# Exploratory Data Analysis-Visualizing your data

## Base R

## ggplot2

```{r}
# TODO: clean up ggplot2 section so that it reads like the rest of the notebook
# clear environment and plotting window -----------------------------------

rm(list = ls())
dev.off()
# set working directory to the Data Days output folder, or wherever your data is stored
setwd("C:/Users/keess/Box/ASA Share/ASA 2020/ASA Meetings/Data Days Spring 2021/Data Days output")

library(tidyverse)

# The Diamonds dataset ---------------------------------
set.seed(123)
df <- slice_sample(diamonds, n = 5000, replace = TRUE)
names(df)

# simple scatterplots of diamond price by carat
df %>%
  ggplot(aes(x = carat, y = price)) +
  geom_point()

# maybe we can make points transparent so we see where they concentrate
p <- df %>%
  ggplot(aes(x = carat, y = price)) +
  geom_point(alpha = 0.1)

# there seems to be a trend. We could look at the trend with a geom_smooth
p_smooth <- p + geom_smooth(method = 'loess', se = F)
p_smooth

# in addition, we can break this plot down into different 'facets' by another variable
p_smooth + facet_wrap(~cut)

# here we split our plot up by different cuts. I've also shown the layered nature of ggplot,
# where graphing elements are added one on top of the other. If we were to write that
# whole plot out using code (and adding labels) it would look like this:
df %>%
  ggplot(aes(x = carat, y = price)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = 'loess', se = F) +
  facet_wrap(~cut) +
  labs(title = "Price vs. Carat, Faceted by Diamond Cut",
       x = 'Carat', y = 'Price', subtitle = "ggplot tutorial for EDA",
       caption = "By Kees Schipper")


# Now let's do the same layered process for a boxplot ---------------------

# start by simply looking at the distribution of price in our entire dataset
df %>%
  ggplot(aes(y = price)) +
  geom_boxplot()

# clearly not very informative. Let's split price into cut
df %>%
  ggplot(aes(x = cut, y = price)) +
  geom_boxplot()

# this gives us a little more information, but we can improve on our boxplot
# aesthetics with notches and outlier colors
df %>%
  ggplot(aes(x = cut, y = price)) +
  geom_boxplot(notch = TRUE, outlier.color = 'blue', fill = 'grey50', color = 'blue')

# we can increase the dimensions accross which we visualize our data by adding
# facets again.

df %>%
  ggplot(aes(x = cut, y = price)) +
  geom_boxplot(outlier.color = 'blue') +
  facet_wrap(~clarity)

# here our notches aren't especially useful, and we also see that labels tend to overlap
# we could try flipping our axes
df %>%
  ggplot(aes(x = cut, y = price)) +
  geom_boxplot(outlier.color = 'blue') +
  facet_wrap(~clarity) +
  coord_flip()

# this is still a little confusing but at least the labels don't overlap
# finally, we can add labels. And let's keep the coordinates as they were originally,
# but we can use the ggplot theme to tilt our x labels
df %>%
  ggplot(aes(x = cut, y = price)) +
  geom_boxplot(outlier.color = 'blue') +
  facet_wrap(~clarity) +
  theme(axis.text.x = element_text(hjust = 0.5, angle = 45)) +
  labs(title = "Price of Different Diamond Cuts, Stratified by Clarity")

# I almost forgot! We can also add summary statistics to our boxplot with stat_summary()
# we can also look at adding jitter so that we can see individual data points in our plots
df %>%
  ggplot(aes(x = cut, y = price)) +
  geom_boxplot(outlier.color = 'blue') +
  stat_summary(fun = 'mean', col = 'red', size = 0.2) +
  geom_jitter(color = 'brown', alpha = 0.10) +
  facet_wrap(~clarity) +
  theme(axis.text.x = element_text(hjust = 1, angle = 45)) +
  labs(title = "Price of Different Diamond Cuts, Stratified by Clarity")


# Now we can look at histograms and density plots -------------------------

# histograms are somewhat easy to implement in ggplot
df %>%
  ggplot(aes(x = price)) +
  geom_histogram(bins = 200) # specify number of bins to increase detail in distribution

# like with other plots, we can color, facet, etc... and we can also stack
# different categories using the position argument
df %>%
  ggplot(aes(x = price, fill = cut)) +
  geom_histogram(bins = 200, position = 'stack')

# this visualization isn't super useful, as we can't see the proportions super
# well. We can change this by using the position = 'fill' option
df %>%
  ggplot(aes(x = price, fill = cut)) +
  geom_histogram(bins = 200, position = 'fill')

# now we can see the relative proportions of what diamonds make up which price
# however, the jitteriness of this plot still isn't fantastic. This is where
# density plots come in
df %>%
  ggplot(aes(x = price, fill = cut)) +
  geom_density(alpha = 0.25, color = "black")

# here we can visualize the smoothed shape of multiple distributions. However,
# it's hard to see the different distributions when they're one on top of the other
df %>%
  ggplot(aes(x = price, fill = cut)) +
  geom_density(position = 'stack', color = "black") +
  facet_wrap(~cut)

# now we can see the proportions of different diamonds making up different prices
# but there's still a better way if we're only interested in proportions
df %>%
  ggplot(aes(x = price, fill = cut)) +
  geom_density(position = 'fill', color = "black")

# Interestingly, all diamond cuts have a dip in the price range of around $4000-5000.
# Maybe this is because jewlers tend to start charging at around $5000, and don't bother
# with mid-range prices.

# A geom halfway between histograms and the densit plot is the 'geom_freqpoly' which
# makes a frequency polygon with jagged edges matching a given number of bins
df %>%
  ggplot(aes(x = price, color = cut)) +
  geom_freqpoly(bins = 50, size = 1) +
  scale_color_hue()


# some other geoms that may be worth trying -------------------------------

# geom hex
df %>%
  ggplot(aes(x = carat, y = price)) +
  geom_hex() +
  scale_fill_viridis_c()

# geom_density_2d
df %>%
  ggplot(aes(x = carat, y = price)) +
  geom_density_2d()

# geom_density_2d_fill
df %>%
  ggplot(aes(x = carat, y = price)) +
  geom_density_2d_filled() +
  geom_density_2d(color = "black") +
  ylim(0, 6000) +
  xlim(0, 1)

# violin plots
df %>%
  ggplot(aes(x = cut, y = price, fill = cut)) +
  geom_violin() +
  facet_wrap(~clarity)

# ?geom_hline
# ?geom_vline

# for all of the geoms, you can type geom_<TAB> and scroll through the autocomplete
# to see what is available
# In my opinion, the R package "viridis" provides some of the best color schemes taht you could
# use for (1) visibility in both color and grayscale, and (2) colorblind friendliness.
# check out the documentation on the viridis color palettes' usage below:
# https://ggplot2.tidyverse.org/reference/scale_viridis.html

# read in data ------------------------------------------------------------
# load in COVID data for all counties across the united states
load('COVID_master_20200218.RData')

# select a county or state that you're interested in:
MACovid <- COVID_master %>%
            filter(state == "Massachusetts" & Population > 0) %>%
            group_by(date) %>%
            summarise(across(where(is.numeric), ~sum(.x, na.rm = T))) %>%
  select(date, cases, deaths:daily_deaths_100k)
# we now have data for the entire state of Massachusetts. If you want to work with
# a different state, change Massachusetts to whatever state that interests you!


# simple visualizations of the data ---------------------------------------
# let's examine a scatterplot of cases in Massachusetts compared to deaths

# this is about as simple a ggplot as you can get. 
ggplot(data = MACovid, aes(x = daily_cases, y = daily_deaths)) +
  geom_point()

# your ggplot specifies global options, so you don't have to specify aesthetics
# in your added geometries. This has benefits and drawbacks...

# We can also store this as a ggplot object and add to it
p <- ggplot(data = MACovid, aes(x = daily_cases, y = daily_deaths))
# p for plot
p # gives us an empty plot with scales corresponding to our data


# adding to a ggplot object -----------------------------------------------

# let's add some points, and a line showing the relationship of our points:
p +
  geom_point() +
  geom_smooth(se = T, span = 0.2, method = "loess", color = 'red') +
  labs(title = "COVID Deaths vs. Cases")

# geom_smooth does a simple loess smoother by default, over our data. Note:
# you don't actually need to plot your points to get a smoother, R knows what
# data you are using, so the smoother is only dependent on your data, not the
# plots that you have in ggplot beforehand

# methods of geom_smooth include linear models (lm) loess, and generalized 
# additve models (gam)


# boxplots ----------------------------------------------------------------
# I'm interested in differences of case and death counts by weekday. Let's get a
# variable for that

MAWeekday <- MACovid %>%
  mutate(weekday = factor(weekdays(date)))

summary(MAWeekday$weekday) # now each observation corresponds to a weekday

# let's plot case counts by weekday
MAWeekday %>%
  ggplot(aes(x = weekday, y = daily_cases)) +
  geom_boxplot() +
  stat_summary(fun = 'mean', color = 'red', geom = 'point')
# now we have boxplots of cases by weekday. We can also add a mean value indicator
# with stat_summary()

# If we like color, we could color weekdays differently
MAWeekday %>%
  ggplot(aes(x = weekday, y = daily_cases, fill = weekday)) +
  geom_boxplot(outlier.alpha = 0) +
  geom_jitter(color = "blue", alpha = 0.2) +
  stat_summary(fun = 'mean', color = 'red', geom = 'point')

# note the difference between specifying color in the aes() function vs in the general
# gemetry. aes() maps a data value to an inherent aspect of ggplot. Therefore, each
# different value of weekday returns a different color. If you specify color or fill
# outside of aes, that singular color is applied to all of the fills and/or colors for 
# that geometry.


# some other interesting geometries ---------------------------------------
# let's accumulate data by week first
week <- 1
daycount <- 0
MAWeekday$week <- 0
for (i in 1:nrow(MAWeekday)){
  print(week)
  MAWeekday$week[i] <- week
  daycount <- daycount + 1
  
  if (daycount == 7){
    
    daycount <- 1
    week <- week + 1
    
  }
}
# create a count of weeks

MAWeek <- MAWeekday %>%
  select(cases, deaths, daily_cases:week) %>%
  group_by(week) %>%
  summarise(across(is.numeric, sum))

# line graphs
MAWeek %>%
  ggplot(aes(x = week)) +
  geom_line(aes(y = daily_cases), size = 1, col = "blue") +
  geom_line(aes(y = daily_deaths), size = 1, col = "red") +
  labs(title = "Comparing Cases and Deaths in Massachusetts")

# geom histogram
MACovid %>%
  ggplot(aes(x = daily_cases)) +
  geom_histogram(bins = 70)

# can even stack histograms 
MACovid %>%
  pivot_longer(cols = c('daily_cases', 'daily_deaths'),
               names_to = 'outcome',
               values_to = 'values') %>%
  ggplot() +
  geom_histogram(aes(x = values, fill = outcome), position = "stack", bins = 30, col = "blue") 

# not the greatest visualization. Let's use a frequency polygon to compare distributions
MACovid %>%
  pivot_longer(cols = c('daily_cases', 'daily_deaths'),
               names_to = 'outcome',
               values_to = 'values') %>%
  ggplot() +
  geom_freqpoly(aes(x = values, color = outcome), size = 1, bins = 50) +
  labs(title = "Now we can see both distributions")


# can even use a density plot as an overlay -------------------------------

MAWeekday %>%
  ggplot() +
  geom_density(aes(x = daily_cases, group = weekday, color = weekday), size = 1) +
  labs(title = "Daily case count density functions by weekday--Hard to see")


# Let's facet! ------------------------------------------------------------
# faceting lets us separate our plots by a factor or character value
MAWeekday %>%
  ggplot() +
  geom_density(aes(x = daily_cases, group = weekday, color = weekday), size = 1) +
  facet_wrap(~weekday) +
  labs(title = "Faceted case counts by weekday--much clearer!!")

# let's look at other variables
MAWeekday %>%
  ggplot() +
  geom_density(aes(x = parks, group = weekday, color = weekday), size = 1) +
  facet_wrap(~weekday) +
  labs(title = "Faceted case counts by weekday--much clearer!!") +
  theme(legend.position = "none") # after faceting, we don't need a legend anymore!


# Let's look at a heatmap/density map -------------------------------------

MAWeekday %>%
  ggplot(aes(x = daily_cases, y = daily_deaths)) +
  geom_density_2d_filled() +
  geom_density_2d(color = 'black') +
  geom_point(color = 'black', alpha = 0.35) +
  scale_fill_brewer(palette = "Reds") +
  ylim(0, 100) +
  xlim(0, 3000) +
  facet_wrap(~weekday)

# Final note on faceting --------------------------------------------------
# if you want to facet your data by a category, your data needs to be in the
# following format (but not in this order):
# x column | y column | faceting column
# because of this, often times you will have to pivot your data for faceting.
# Let's do this to look at the relationships between deaths, cases, and mobility
# over time

facet_data <- MAWeekday %>%
  pivot_longer(cols = c('retail_rec':'daily_deaths'),
               names_to = 'vars',
               values_to = 'values') %>%
  select(date, vars, values, weekday)

facet_data %>%
  ggplot(aes(x = date, y = values)) +
  geom_line(aes(color = vars))

# see...not the most visible data. Much easier to facet

facet_data %>%
  ggplot(aes(x = date, y = values)) +
  geom_line(aes(color = vars)) +
  facet_wrap(~vars)

# you can also facet by multiple variables. You just need to use `facet_grid` and
# specify the column facet, and the row facet
facet_data %>%
  ggplot(aes(x = date, y = values)) +
  geom_line(aes(color = vars)) +
  facet_grid(cols = vars(vars), rows = vars(weekday), scales = 'free_y') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))




# Further resources -------------------------------------------------------

# for more on visualizations in R, I always point people to the R graph gallery:
# https://www.r-graph-gallery.com/
# if you have an idea for a visualization, there is likely some code already in the
# gallery that can get you started on making your final visualization. If you're stuck
# I recommend checking it out.
```





